<?xml version="1.0" encoding="UTF-8"?>
<!-- Licensed under the Apache License, Version 2.0 (the "License"); you 
	may not use this file except in compliance with the License. You may obtain 
	a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless 
	required by applicable law or agreed to in writing, software distributed 
	under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES 
	OR CONDITIONS OF ANY KIND, either express or implied. See the License for 
	the specific language governing permissions and limitations under the License. 
	See accompanying LICENSE file. -->
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<properties>
		<spark.version>2.3.0</spark.version>
		<cupid.sdk.version>3.3.8-public</cupid.sdk.version>
		<scala.version>2.11.8</scala.version>
		<scala.binary.version>2.11</scala.binary.version>
		<maven.compiler.source>1.8</maven.compiler.source>
		<maven.compiler.target>1.8</maven.compiler.target>
	</properties>

	<groupId>com.launch.bigdata</groupId>
	<artifactId>bigdata-dw-odpsspark</artifactId>
	<version>1.0.0-SNAPSHOT</version>
	<packaging>jar</packaging>
	<dependencyManagement>
		<dependencies>
			<dependency>
				<groupId>io.netty</groupId>
				<artifactId>netty-all</artifactId>
				<version>4.1.42.Final</version>
			</dependency>
		</dependencies>
	</dependencyManagement>

	<dependencies>
		<dependency>
			<groupId>jdk.tools</groupId>
			<artifactId>jdk.tools</artifactId>
			<version>1.8</version>
			<scope>system</scope>
			<systemPath>${JAVA_HOME}/lib/tools.jar</systemPath>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
			<exclusions>
				<exclusion>
					<groupId>org.scala-lang</groupId>
					<artifactId>scala-library</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.scala-lang</groupId>
					<artifactId>scalap</artifactId>
				</exclusion>
				<exclusion>
					<groupId>io.netty</groupId>
					<artifactId>netty-all</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>


		<dependency>
			<groupId>com.aliyun.odps</groupId>
			<artifactId>cupid-sdk</artifactId>
			<version>${cupid.sdk.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>com.aliyun.odps</groupId>
			<artifactId>hadoop-fs-oss</artifactId>
			<version>${cupid.sdk.version}</version>
		</dependency>

		<dependency>
			<groupId>com.aliyun.odps</groupId>
			<artifactId>odps-spark-datasource_${scala.binary.version}</artifactId>
			<version>${cupid.sdk.version}</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-actors</artifactId>
			<version>${scala.version}</version>
		</dependency>

		<!-- <dependency> <groupId>com.aliyun.odps</groupId> <artifactId>cupid-core_2.11</artifactId> 
			<version>1.0.0</version> <scope>provided</scope> </dependency> <dependency> 
			<groupId>com.aliyun.odps</groupId> <artifactId>cupid-datasource_2.11</artifactId> 
			<version>1.0.0</version> <scope>provided</scope> </dependency> <dependency> 
			<groupId>com.aliyun.odps</groupId> <artifactId>cupid-client_2.11</artifactId> 
			<version>1.0.0</version> <scope>provided</scope> </dependency> -->




		<!-- hbase 依赖 -->
		<dependency>
			<groupId>com.aliyun.hbase</groupId>
			<artifactId>alihbase-client</artifactId>
			<version>1.1.9</version>
			<exclusions>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-yarn-common</artifactId>
				</exclusion>
				<exclusion>
					<groupId>io.netty</groupId>
					<artifactId>netty-all</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-common</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-mapreduce-client-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-auth</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
	</dependencies>

	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-jar-plugin</artifactId>
				<configuration>
					<archive>
						<manifest>
							<addClasspath>true</addClasspath>
							<classpathPrefix>lib/</classpathPrefix>
							<mainClass>com.launch.bigdata.spark.SparkOdpsToHbase</mainClass>
						</manifest>
					</archive>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<configuration>
					<skipTests>true</skipTests>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<version>2.4.3</version>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
						<configuration>
							<minimizeJar>false</minimizeJar>
							<shadedArtifactAttached>true</shadedArtifactAttached>
							<artifactSet>
								<includes>
									<!-- Include here the dependencies you want to be packed in your 
										fat jar -->
									<include>*:*</include>
								</includes>
							</artifactSet>
							<filters>
								<filter>
									<artifact>*:*</artifact>
									<excludes>
										<exclude>META-INF/*.SF</exclude>
										<exclude>META-INF/*.DSA</exclude>
										<exclude>META-INF/*.RSA</exclude>
										<exclude>**/log4j.properties</exclude>
									</excludes>
								</filter>
							</filters>
							<transformers>
								<transformer
									implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
									<resource>reference.conf</resource>
								</transformer>
								<transformer
									implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
									<resource>META-INF/services/org.apache.spark.sql.sources.DataSourceRegister</resource>
								</transformer>
							</transformers>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<!-- <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-shade-plugin</artifactId> 
				<version>3.0.0</version> <executions> <execution> <phase>package</phase> 
				<goals> <goal>shade</goal> </goals> </execution> </executions> <configuration> 
				<relocations> <relocation> <pattern>com.google.protobuf</pattern> <shadedPattern>com.iteblog.google.protobuf</shadedPattern> 
				</relocation> </relocations> </configuration> </plugin> -->
			<!-- <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-shade-plugin</artifactId> 
				<version>2.4.3</version> <executions> <execution> <phase>package</phase> 
				<goals> <goal>shade</goal> </goals> <configuration> <minimizeJar>false</minimizeJar> 
				<shadedArtifactAttached>true</shadedArtifactAttached> <artifactSet> <includes> 
				Include here the dependencies you want to be packed in your fat jar <include>*:*</include> 
				</includes> </artifactSet> <filters> <filter> <artifact>*:*</artifact> <excludes> 
				<exclude>META-INF/*.SF</exclude> <exclude>META-INF/*.DSA</exclude> <exclude>META-INF/*.RSA</exclude> 
				<exclude>**/log4j.properties</exclude> </excludes> </filter> </filters> <transformers> 
				<transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer"> 
				<resource>reference.conf</resource> </transformer> <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer"> 
				<resource>META-INF/services/org.apache.spark.sql.sources.DataSourceRegister</resource> 
				</transformer> </transformers> </configuration> </execution> </executions> 
				</plugin> -->
		</plugins>
	</build>

</project>
